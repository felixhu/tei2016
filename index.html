<!DOCTYPE html>
<html>
  <head>
    <meta charset='UTF-8'>
    <title>Strawbies (TEI 2016)</title>
    <link rel="stylesheet" type="text/css" href="css/acm-sig.css">
    <link rel="stylesheet" media="print" type="text/css" href="css/acm-sig-print.css">
    <script src="js/cssregions.js"></script>
    <script src="js/acm-references.js"></script>
    <style>
    #figure1 {
      position: absolute;
      bottom: 0;
      right: 0;
      width: 3.33in;
      height: 3.0in;
    }

    #figure2 {
      position: absolute;
      top: 0;
      right: 0;
      width: 7in;
      height: 2.5in;
    }

    #figure3 {
      position: absolute;
      bottom: 0;
      right: 0;
      width: 3.33in;
      height: 4.2in;
    }

    #figure4 {
      position: absolute;
      top: 0;
      right: 0;
      width: 3.33in;
      height: 2.5in;
    }

    #figure5 {
      position: absolute;
      bottom: 0;
      left: 0;
      width: 3.33in;
      height: 4.2in;
    }

    #figure6 {
      position: absolute;
      bottom: 0;
      left: 0;
      width: 3.33in;
      height: 5.0in;
    }

    .highlight {
      background-color: yellow;
    }
    </style>
  </head>
  <body onload="generateReferenceList();">

    <!-- Page 1 -->
    <div class="page">
      <div class="page-content">
        <div id="citation"> </div>
        
        
        <div class="title">Strawbies: Designing an inexpensive, portable, and fluid tangible programming game</div>
        <br>
        <table style="width: 100%; margin-top: 10px;">
        <tr>
          <td class="authors">Author 1</td>
          <td class="authors">Author 2</td>
          <td class="authors">Author 3</td>
        </tr>
        <tr style="vertical-align: top;">
        </tr>
        </table>
        <br><br><br>

        <div class="copyright">
          Copyright notice.
        </div>
        
        <div class="column left" style="height: 6.4in;"></div>
        <div class="column right" style="height: 4.5in"></div>

        <figure id="figure1">
          <img src="figures/figure1.png" style="width: 3.33in; height: 2.5in" alt="">
          <figcaption>
            Figure 1. Strawbies programming environment using tangible tiles, an iPad, and the Osmo attachment.          
            <!--
            Figure 1. Child playing with Strawbies using tangible tiles, an iPad, and the Osmo attachment.
            -->
          </figcaption>
        </figure>

        <div class="page-footer"></div>
      </div>
    </div>

    
    <!-- Page 2 -->
    <div class="page">
      <div class="page-content">
        <div class="column left"></div>
        <div class="column right"></div>
        <div class="page-footer"></div>
      </div>
    </div>

    
    <!-- Page 3 -->
    <div class="page">
      <div class="page-content">
        <div class="column left" style="margin-top: 2.3in; height: 6.65in;"></div>
        <div class="column right" style="margin-top: 2.3in; height: 3.1in;"></div>

        <figure id="figure2">
          <img src="figures/figure2.png" style="width: 7in; height: 1.845in" alt="">
          <figcaption>
            Figure 2. Collection of programming tiles available to guide the character in search of stawberries.
          </figcaption>
        </figure>

        <figure id="figure3">
          <img src="figures/figure3.png" style="width: 3.33in; height: 3.33in" alt="">
          <figcaption>
            Figure 3. Our first three major iterations of block design. 
          </figcaption>
        </figure>

        <div class="page-footer"></div>
      </div>
    </div>

    
    
    <!-- Page 4 -->
    <div class="page">
      <div class="page-content">

        <figure id="figure4">
          <img src="figures/figure4.png" style="width: 3.33in; height: 2.3in" alt="">
          <figcaption>
            Figure 4. We quickly went through different symbols to find out which made the most sense to our players. 
          </figcaption>
        </figure>

        <div class="column left"></div>
        <div class="column right" style="margin-top: 2.7in; height: 6.4in;"></div>
        <div class="page-footer"></div>
      </div>
    </div>

    <!-- Page 5 -->
    <div class="page">
      <div class="page-content">
        <div class="column left" style="height: 4.9in;"></div>
        <div class="column right"></div>

        <figure id="figure5">
          <img src="figures/figure5.png" style="width: 3.33in; height: 3.74in" alt="">
          <figcaption>
            Figure 5. A player tapping to compile their constructed sequence.
          </figcaption>
        </figure>

        <div class="page-footer"></div>
      </div>
    </div>

    <!-- Page 6 -->
    <div class="page">
      <div class="page-content">
        <div class="column left" style="height: 4.0in"></div>
        <div class="column right" style="height: 8.9in"></div>

        <figure id="figure6">
          <img src="figures/figure6.png" style="width: 3.33in; height: 4.0in" alt="">
          <figcaption>
            Figure 6. Different iterations of our game.
          </figcaption>
        </figure>

        <div class="page-footer"></div>
      </div>
    </div>

    <!-- Page 7 -->
    <div class="page">
      <div class="page-content">
        <div class="column left"></div>
        <div class="column right"></div>
        <div class="page-footer"></div>
      </div>
    </div>
    
    
    <div id="article-content">
      <h1 class="no-number">Abstract</h1>
      <p>
        Strawbies is a tangible programming game designed for children ages 5 and up. Players arrange physical programming tiles to guide the movement of an onscreen character (Awbie) through an infinitely expanding world displayed on the screen of an iPad. Strawbies is portable, inexpensive, and fluidly interactive—characteristics made possible with the use of an Osmo game system that includes a mirror to reflect images in front of the iPad through the front­-facing camera. Here we describe a set of principles that guided our design process along with evaluation sessions with children in schools and a museum. The combination of inexpensive tangible tiles and real-time computer vision through a tablet computer opens new possibilities for tangible computer programming to reach a broader audience. We conclude with an overview of the important design considerations for future tangible programming systems that make use of these techniques.
      </p>
      
      <h2 class="no-number">Categories and Subject Descriptors</h2>
      <p style="text-align: left;"> H.5.m [<b>Information interfaces and
          presentation (e.g., HCI)</b>]: Miscellaneous.
      </p>
      
      
      <h2 class="keywords no-number">Keywords</h2>
      <p>
        Children; programming; tangibles; games; strawberries.
      </p>
      
      
      <h1>Introduction</h1>
      <p>
        Strawbies is a tangible programming game designed for children ages 5 and up that combines the use of inexpensive tangible tiles and real-time computer vision through a stationary iPad tablet (Figure 1). Players arrange wooden tiles to guide the movement of an onscreen character (Awbie) through a rich and infinitely expanding world filled with obstacles, thieving rodents, and strawberries. Strawbies is portable, inexpensive, and fluidly interactive. These features are made possible by the use of an Osmo game system (playosmo.com) that uses a mirror to reflect images in front of the iPad through the front­-facing camera. In creating Strawbies, we sought to explore new possibilities opened by this system to create an engaging and collaborative game for wide range of ages and playstyles.
      </p>
      <p>
        To this point, tangible programming systems have had to make tradeoffs between inexpensive materials, portability, and real-time interaction. Many tangible programming systems have opted to use “smart” tangible components with embedded electronics and power supplies (e.g. [<cite ref="schweikardt-2008"></cite>, <cite ref="mcnerney-2004"></cite>, <cite ref="wyeth-2008"></cite>]). This has the advantage of offering real-time interactive systems that can be used anywhere, with the downside that these systems are relatively expensive to create and manufacture. Other tangible programming systems have instead opted to use computer vision and “passive” tangible blocks or tiles (e.g. [<cite ref="horn-2012"></cite>]). But, the ability to continuously track and respond to programming blocks has either required a stationary overhead camera fixture or an interactive surface with built-­in camera hardware. It is possible to instead use a mobile device like an iPad, but this requires a point-­and­-shoot style of interaction (e.g. [<cite ref="kibo-2015"></cite>, <cite ref="roberto13"></cite>]) in which real-time interaction is sacrificed for the sake of portability. The Osmo's use of a mirror over the top of the iPad’s front-facing camera makes it possible to obtain the best of both worlds by combining fluid, real-­time interaction with a mobile device and low-­cost tangible materials. 
      </p>
      <p>
        We believe that these characteristics open opportunities for designers to create engaging tangible programming systems that are accessible to a much broader audience. Our aim with Strawbies is to explore this design space. Early on we discovered that despite the innovation of the Osmo, achieving our design goals was more difficult than we anticipated. We struggled with both the game design and the programming block design over many iterations before we felt that we had achieved a system that was inviting, engaging, and easy for children to learn with. Testing sessions with children in homes, schools, out-of-school programs, and a children’s museum offered us quick feedback and helped us articulate design principles to support a versatile and engaging programming game. In this paper we describe our design process in more detail and share insights from our evaluation sessions. 
      </p>

      <h1>Related Work</h1>
      <p>
        Our project builds on a long and rapidly growing tradition of programming environments for young children 
        [<cite ref="disessa-2000"></cite>, 
        <cite ref="scratchjr13"></cite>, 
        <cite ref="horn-2013"></cite>, 
        <cite ref="montemayor-2004"></cite>, 
        <cite ref="oh-2013"></cite>,
        <cite ref="papert-1980"></cite>, 
        <cite ref="resnick-2009"></cite>,
        <cite ref="roblocks08"></cite>,
        <cite ref="sapounidis-2013"></cite>,
        <cite ref="sipitakiat-2012"></cite>,
        <cite ref="sullivan-2015"></cite>,
        <cite ref="weintrop-2013"></cite>,
        <cite ref="wyeth-2008"></cite>]
        (see also [<cite ref="mcnerney-2004"></cite>] for an excellent account of older work dating back to the 1970s). 
        There is also growing momentum around the idea of supporting computational literacy activities throughout K-12 education, starting at the earliest grade levels. Our project contributes to this space by blending the flexibility, portability, and practicality of tangible programming with an open-ended formatting, which enables our game to be highly responsive to the spontaneity in early childhood learning.
      </p>

      <h1>Design Principles</h1>
      <p>
        Strawbies began as an exploration into using the Osmo to create a tangible programming environment. As part of our design process we settled on several principles that articulated both a set of pedagogical values and the kind of experience we hoped to create.
      </p>
      <p>
        <b>Fun and Inviting:</b> We sought to create a game that was entertaining, attractive, and not intimidating. We hoped that the tangible objects would attract kids’ attention from a distance and draw them into an engaging experience.
      </p>
      <p>
        <b>Collaborative:</b> Research in the learning sciences suggests that kids spontaneously form diverse and effective patterns of collaboration in game play [<cite ref="nasir-2005"></cite>, <cite ref="stevens-2008"></cite>]. Our observations of children playing Strawbies corroborated these findings with siblings, classmates, and friends engaging in a surprising variety of joint activity. It was important, therefore, that our game create space for diverse collaborative arrangements with two, three, and even four or more.
      </p>
      <p>
        <b>Responsive:</b> It was important for the game to support fluid and real-time interaction. As much as possible we wanted the game to “responds immediately, clearly and predictably to users’ actions.” [<cite ref="snibbe-2009"></cite>]
      </p>
      <p>
        <b>Simple but Complex:</b> Even though we limited ourselves to a relatively small library of programming tiles, we wanted to create enough complexity in the combination of these blocks for the game to remain compelling for longer play sessions or more experienced players. 
      </p>
      <p>
        <b>Developmentally Aligned:</b> We wanted to ensure that the content of our game was aligned with the cognitive, perceptual­-motor, and social ability of our target audience.
      </p>
      <p>
        <b>Portable:</b> The system must be easy to setup and transport to classrooms, museums, homes, after-school programs, summer camps, etc.
      </p>
      <h2 class="no-number">Learning Goals</h2>
      <p>
        Our target age range is 5 and up. Our learning goals were structured for children who have had little or no experience with programming languages.
      </p>
      <p>
        <b>Sequencing:</b> The game should familiarize and reinforce players with the concept of using sequences of blocks to construct plans.
      </p>
      <p>
        <b>Intrinsic Integration:</b> Intrinsic Integration [<cite ref="habgood-2011"></cite>] is a principle from the learning sciences that argues that the best and most fun parts of a game should also be where the important learning is taking place. This is in contrast to using incentives to motivate players to engage in activities that would otherwise be seen as tedious.
      </p>
      <p>
        <b>Slow Learning Progression:</b> We didn’t want to force kids to create longer, more complex programs right away. In fact, it’s possible to play the game using only one or two blocks at a time, never picking up a repeat block and never creating a sequence. Instead, we sought to subtly encourage (but never force) kids to explore new concepts, at their own pace, and only when they are ready. 
      </p>

      <h1>Design Overview</h1>
      <p>
        Our current iteration of Strawbies features an infinitely expanding world filled with obstacles, adversarial characters, and strawberries (Figure 1). Players slide and connect coding tiles in front of an iPad to guide Awbie on his quest for more strawberries. Obstacles include trees, cactuses, and water that can derail you from a strategically planned sequence of instructions. Large rodent characters will also steal berries from Awbie. Getting multiple strawberries with one sequence triggers Frenzy Mode, causing Awbie to go into a fun frenzy and eat even more strawberries. Lakes with lilypad paths and treasure islands are designed to encourage the use more complex sequences of programming tiles. Large bouncing strawberries are scattered throughout the world, which lead to short tutorials that show possible patterns using different sequences of blocks. 
      </p>
      <p>
        The game includes six action blocks: Up, Down, Right, Left, Rainbow, Flashlight. The direction blocks moved Awbie in the specified direction, Rainbow transported Awbie into a different part of the world, and Flashlight scared away rats. There were parameter blocks (1, 2, 3 or 4) that attach to action blocks and multiply the times an attached direction block executes. Repeat blocks can also be used to repeat the entire sequences of tiles multiple times depending on the quantifier block used. (Figure 2)
      </p>

      <h1>Participants</h1>
      <p>
        We formally evaluated our design with 29 children in two locations. Our first round of testing was with five kindergartners and five 2nd graders at a local elementary school (4 boys and 10 girls). Children participated in groups of two or three peers from the same grade, with each session lasting around 15 minutes. We started each session with minimal instruction and then allowed children to explore on their own. At the very end of each session, we prompted students to try repeat tiles and parameter values if they had not already. 
      </p>
      <p>
        Our second round of testing involved 7 sessions with 8 boys and 7 girls at a local children’s museum (ages 5 to 10). Children in these sessions occasionally worked alone, but more often in groups of 2 or 3. There was no set time limit, but sessions generally lasted between 3 and 15 minutes, with one pair of siblings spending over 40 minutes (average session length 14:30). Parents were also invited to participate but, for the most part, allowed children to explore on their own. All sessions at both locations were video recorded with informed consent of parents and children.
      </p>
      <p>
        We also conducted many rounds of informal testing with children at a local elementary school, two out-of-school programs, and in homes. We did not collect research data in these informal sessions but instead used them to test and refine our design. 
      </p>

      <h1>Design Process and Evaluation</h1>
      <p>
        Our design process included several major iterations in which we explored different approaches for the iPad app and tangible programming tiles. Here we describe specific categories of the design and important decisions.
      </p>
      <p>
        Each feature generally began with ideas heavily borrowed from existing successful languages such as Scratch. As we tested these features, we modified and redesigned them as necessary.
      </p>

      <h2 class="no-number">Block Design</h2>
      <p>
        The most common actions when playing with a tangible programming environment is connecting and detaching coding blocks. We wanted to create blocks that could easily attach and detach, yet maintain structural integrity. We also wanted our blocks to intuitively connect together, without the need of any tutorials.
      </p>
      <p>
        We went through several iterations of connection techniques, ultimately settling on two different connection types. The first connection technique is an arrow-hook that attaches action blocks together. This connector allowed action blocks to be attached on a surface only by sliding. The connection was also secure enough such that users could move attached blocks around on a surface without them coming apart. The design was intuitive for our users, as there is an arrow-shaped gap on each action block, invoking the action of connection. We experimented with two previous iterations of connection techniques: our first iteration was too cumbersome to attach, and our second iteration was too easily detached (Figure 3).
      </p>
      <p>
        The second connection technique was inspired by the circular nature of the TopCode design. We used this connector to attach quantifier and action blocks. Our third iteration of blocks featuring TopCodes allocated a large amount of block space to the TopCode itself (Figure 3). By incorporating TopCodes into our connection technique, we were able to add illustrations to the blocks, without increasing the size of the blocks which was undesirable due to the already limited play space defined by the Osmo. 
      </p>
      <h3>Evaluation</h3>
      <p>
        We observed two girls in Kindergarten playing Strawbies in a classroom for a 30 minute session. In this session, one girl, Player 1, had played Strawbies before, months back. The other girl, Player 2, had never played Strawbies. When the game started, Player 1 assumed full control of the game, immediately acquiring strawberries. This went on for almost 8 minutes, while Player 1 explained to Player 2 how to play the game. We observed that Player 1 was only playing the game using individual commands. As Player 2 played with blocks, she began constructing more elaborate sequences, without prompts from the game. After 8 minutes, Player 2 suggested that they try out her constructed sequence.
      </p>
      <!--
      <p>
        Our current blocks are fun and inviting: they use colorful illustrations, and are thick and fun to play with. They are simple and complex: players can construct more elaborate sequences, only if they wish. They are developmentally appropriate: they contain symbols as well as words, and invoke connection.
      </p>
      -->
      <h2 class="no-number">Navigation</h2>
      <p>
        Navigating the world of Strawbies was the biggest roadblock for our players, and we went through several iterations to try and fix the problem (Figure 4). There were two important choices that we made: relative vs. absolute directionality, and separating vs. combining movement and direction blocks.
      </p>
      <p>
        Separating out the action of turning one's body from the action of moving forward is appropriate for many programming systems (such as the Logo turtle). However, for the purposes of our game, we found that absolute directionality (face left, right, up, down) was easier for players to learn. 
        <!-- 
        We experimented with using relative directionality, having some success after finding the right diagram [Figure]. We concluded that turning was too difficult to visualize in a digital screen with a top-down view, and was not conducive to planning.
      </p>
      <p>
        We chose combining movement and direction blocks over keeping them separate. For example, the two block command “Left, Walk” became just “Left”. Despite numerous attempts to show that a “Left” block actually meant “face left” [Figure], players still assumed that a Left block meant move left. 
        -->

        Grammatically, keeping turning and walking separate also did not make sense. In English, people say “walk left”, but in our game, “Walk, Left” wouldn’t make sense; the character would first move in the direction that it is currently facing, then turn left. Lastly, combining movement and direction blocks is concise, reducing the number of blocks needed by half.
      </p>
      <h3>Evaluation</h3>
      <p>
        We observed two siblings, a boy and girl, playing Strawbies in a children’s museum for 40 minutes. The siblings were collaborative, and often discussed where they should go with phrases like “oh look there’s two strawberries down there!” and “no we should go left first then down this way we can get more”. Their constructed sequences consisted of 1-3 blocks, often detaching and attaching different sequences to fit Awbie’s situation. As the two siblings watched Awbie navigate their constructed sequences, we noticed that they were consistently saying each commands as Awbie executed them. This was something that we had only noticed once before combining movement and direction blocks, but became a common trend after.
      <!--
      </p>
      <p>
        Our navigation blocks are developmentally aligned: children did not struggle with translating their plans into action blocks. Instead we saw a lot of verbal repeating of commands as Awbie executed them, which we thought could be a sign that our direction blocks are aligned with their cognitive perception. 
-->
        We also found that the blocks with absolute directions were better at supporting sequencing. The new commands are more concise and allow for more elaborate planning. We saw an increase in the complexity of constructed sequences upon combining movement and direction blocks. 
      </p>

      <h2 class="no-number">Feedback</h2>
      <p>
        Children are constantly constructing conceptual models to explain how things in the world work [<cite ref="norman-2013"</cite>]. We needed Strawbies to provide immediate, consistent, and clear feedback to our players, without which they would develop false beliefs about how the system worked. We tried to provide feedback about the blocks currently in the camera's field of view in a way that was immediate without being distracting or disruptive. Aside from the natural feedback provided by feeling and connecting tangibles, our feedback was limited to the digital space. Our passive tangibles, which are laser cut from wood, cannot provide any kind of ‘smart’ feedback.
      </p>
      <p>
        We explored several options before settling on our current iteration. 

        We first used half the screen to show a representation of what the camera sees (Figure 6). When a player slid a sequence in front of the iPad, a digital replica of the blocks would appear on the screen. After testing, we decided that this was redundant and  took up too much screen space.
      </p>
      <p>
        We then placed a live video-feed from the game’s camera in the upper right corner, which circled TopCodes in red as they were recognized (Figure 6). We wanted this to bridge the connection between the physical and digital. Despite numerous verbal prompts during testing, we were unable to get children to pay attention to the video feed. Since it did not appear to help children understand what was going on, we removed this feature. 
      </p>
      <p>
        Our current iteration integrates feedback with gameplay. We project a path of Awbie’s future actions onto the world (Figure 1, 6). The path animates incrementally from Awbie to visualize his potential movement. We felt that this was clear and immediate, but not disruptive or distracting. We hoped this projection will assist our players in the construction of more elaborate plans. 
      </p>
      <h3>Evaluation</h3>
      <p>
        After the introduction of a projected path, children began modifying their sequence by adjusting the location of their sequence upon seeing different projections than what they had in mind. We also saw players construct more elaborate plans. We observed three Kindergarten students, 2 girls and 1 boy, in a classroom playing Strawbies for 30 minutes. 4 minutes into the game, the children were unable to compile their code, because they were all reaching for the screen and tapping the screen, blocking the TopCodes from being read. One girl shooed away the other players hands, and said “the path needs to be there!” (referincing the screen). 8 minutes into the game, the boy had a sequence that would have run Awbie into a rodent. The two girls yelled, “no! we don’t want to touch it.” The girls then replaced a direction block.
      </p>
      <!--
      <p>
        The projected path is collaborative: players can agree on a path before compiling. The path is developmentally aligned: our players quickly understood the purpose of the path, and was able to use it effectively. The path helped players create accurate and thoughtful plans, and also led players to troubleshoot when the path was different from the constructed physical sequence. 
      </p>
      -->
      <p>
        We are working on making our feedback more responsive. The path projection reacts quickly to blocks that are recognized (under 1.5 seconds), but it is not immediate. Without immediate feedback, some children will quickly move blocks around, hoping for something to happen on screen. This action however only exacerbates issues with the computer vision, causing feedback to no longer be clear or predictable. 
      </p>

      <h2 class="no-number">Compiling</h2>
      <p>
        Many tangible programming environments provide users with input events that trigger the system to compile and run their code. The alternative is to have system continually evaluate code so that changes in arrangment of programming blocks is instantaneously reflected in a runtime environment. Using real-time computer vision opened both of these possibilities. 
      </p>
      <p>
        Our initial reaction was to keep as much interaction to the tangible interface as possible and evalute programs in real time. When blocks slid in front of the game’s field of vision, the on-screen character immediately responded by following and continually looping those instructions. When blocks were moved away, the character immediately stopped. 
        <!-- If the user attached a When block to any sequence of blocks, the game would pause and bring up a helper which asked if players wanted to save the event block to memory. We wanted our players to think of optimal loops for the world, with event triggers that act as safeguards against dangers (water and birds). -->
      </p>
      <p>
        The responsiveness of this real-time interactivity was immediate, but not clear or predictable. Our play testers had trouble maintaining control over their character, and often relied on using hands to cover up blocks when they wanted their character to stop; moving blocks outside of the camera’s range was too tedious. The field of vision of the camera was also unclear. Sometimes, the camera would pick up blocks that a player forgot about, resulting in unexpected effects.
      </p>
      <p>
        Our current iteration instead uses a tap on the screen as the triggering event (Figure 5). Players can easily reuse their sequence simply by re-tapping the screen. Once the screen is tapped, blocks can be removed from the game’s vision without affecting the game.
        <!-- 
         This mechanism also has the added benefit of immediately demonstrating that Strawbies can be tapped as well as controlled by tangibles. Without this quick introduction, it was hard to get our users to tap the screen without explicit tutorials. 
         -->
      </p>
      <p>
        The disadvantage of this mechanism is that when users tap the screen, their arm can block a portion of the image that is sent to the game. We tried to resolve this issue by making the tap box of the iPad almost the entire size of the screen, and added a one second delay to the game’s image recognition.
      </p>
      <h3>Evaluation</h3>
      <p>
        We observed players to compile their code in different ways. Some tapped in the direction they wanted Awbie to go, and others tried to drag Awbie around the screen. We weren’t worried about this behavior, as tapping to compile was an open enough mechanic such that many similar motions achieved the same effect. Eventually, as players constructed more elaborate sequences, tapping to compile became the predominant action. 
      </p>
      <p>
        Camera occlusion problems were more problemmatic. We observed two girls in Kindergarten playing Strawbies in a 30 minute session. The girls had no problem touching the screen to compile their code. However, for the first 10 minutes, they kept their finger on the screen in the direction of movement until the character stopped. It seemed that they thought Awbie was controllable by dragging as well. While one girl kept her finger on the screen, the other girl shifted blocks around below the girl’s arm. The camera was not able to see the full picture because the blocks were occluded by the girl’s arm, resulting in inconsistent and confusing actions from Awbie. 
      </p>
      <!--
      <p>
        After 10 minutes, they wanted to try the “Rainbow” command, a new block that had no path projection. The girls simply tapped the screen, and watched what happened. After this, the girls started to only tap the screen to compile. A few minutes later, the dragging behavior came back when Awbie was not moving as they had planned.
      </p>
      -->
      <p>
      <!--
        There were a lot of times where Strawbies was very unresponsive. This happened when hands blocked the camera from seeing the blocks. Players took minutes to figure out that they had to move their hands away before the game could respond. 
      -->
        These kinds of problems are acceptable in a classroom setting, where children had time to familiarize themselves with the game, but they are less ideal for a more informal learning settings like museum. We are hoping to rectify this problem in our next tutorial by introducing a tangible trigger that will not require children to touch the screen at all. 
        <!-- mat which contains two compile buttons that must be simultaneously pushed. -->
      </p>

      <h2 class="no-number">Open World Environment</h2>
      <p>
        Our first iteration of the game had a linear narrative structure, consisting of a series of maze-like puzzles (Figure 6). Players puts down a sequence of blocks, pressed start, and watched the character navigate through the puzzle. If the character ran into water, the level would restart from the beginning. This style was heavily influenced by Hour of Code’s Introduction to Code series [<cite ref="hour-of-code"></cite>]. But we found that this approach was not motivating or effective in open and collaborative spaces with multiple players on the same device. It was difficult for players to collaborate when there was only one answer to a problem. New players also had trouble understanding the game, as each new level used ideas introduced in previous levels. 
        <!-- The game was also all around difficult, and failed to be engaging. -->
      </p>
      <p>
        For the next iteration, we moved away from the classic puzzle game [<cite ref="flanagan-2009"></cite>], which tends to emphasize competitive and linear play with only one (or a small number) of correct answers. We instead focused on developing a game which encouraged collaboration between players across different experience levels and ages by supporting different play-styles.
        <!--  This meant that we had to create a more networked game, one which had real decisions with equally plausible outcomes. [CITE] -->
      </p>
      <p>
        We decided instead to structure our game around a randomly generated open world environment, filled with interactable objects like strawberries, rats, cactuses, trees, water, animals, and more (Figure 6). We took out win/lose states, and instead introduced a more gradual build up of possessions that players could acquire. For example, finding seeds in the world allows you to grow strawberry plants in your farm. Making contact with undesired objects such as rats and cactuses sets Awbie off of a projected path, which deter players from further running into obstacles.
      </p>
      <p>
        We hoped that an expansive world filled strawberries and other objects would encourage more open-ended and light-hearted collaboration There are no wrong answers. We also wanted to encourage planning, but wanted to do it in a way that was less forced and more fun. 
      </p>
      <p>
        There was still structure in the game. We introduced lakes, with lilypads that lead to a treasure island in the middle (Figure 6). To get to the island, players must use a sequence of blocks that would guide the character all the way to the island. The character falls into the water if it takes a misstep and is transported back to the start of the lake. This give players the option to explore more difficult puzzles, but they are also free to skip the lake and move on if they want.
      </p>
      <p>
        We also introduced “Frenzy Mode”, a fun animation that Awbie goes into when he is about to get multiple Strawbies with one sequence of blocks. This results in more Strawbies, a quicker movement speed, and playful animations. We felt that this was another example of adding structure into what is otherwise an open world game.
      </p>
      <h3>Evaluation</h3>
      <p>
        We noticed a big change in how players interacted with the game after we introduced the open-world environment. We heard a lot more conversations about decisions and goals, much like this excerpt from a conversation between two boys in Grade 2: P1: “Let’s keep going. Wait actually I think I see up” P2: “No I think we should go down.” P1: “Yeah but if we go up we can use Tornado!”.
      </p>
      <p>
        We also observed groups of children with different tendencies play together. In one example, a boy and girl in Kindergarten are playing, and the boy continuously to Rainbow around the world. The girl says “See! We’re not getting any Strawbies.” After some discussion, the boy conceded, and the girl moved her sequence of blocks in front of the iPad.
      </p>
      <p>
        Lakes were also effective. Many of our players understood that a more exact and elaborate sequence was necessary to reach the middle treasure island. Some players attempted to solve the puzzle, but others moved on to other goals. We saw the same behavior with Frenzy Mode. Many children only attempted chaining upon reaching a large obvious chain of Strawbies, while others attempted chaining at every possibility. Players showed signs of delight when they pulled off a successful chains.
        <!-- , and we thought that was a good example of integrated learning.-->
      </p>
      <!--
      <p>
        The open world environment is fun and inviting: players can come and go with ease, and play the game how they wish. The environment is collaborative, supporting typical classroom struggles such turn-taking, sharing, and differing goals. The environment is simple and complex: players can learn at their own pace, and build more complex sequences as they wish. 
      </p>
      -->
      
      <h1>Conclusion</h1>
      <p>
        We were able to create an inexpensive, portable, and fluid tangible programming environment by using the Osmo play system. Portability allowed for players to play Strawbies in a range of spaces. Inexpensive and passive tangibles allowed us to rapidly prototype and iteratively design our game. Fluidity allowed for a truly engaging experience that kept our players playing.
      </p>
      <p>
        Through our long and iterative design process, we learned lessons that we believe are important for similar programming environments that combine real-time computer vision with inexpensive tangible compontents. Games should be designed using existing tablet interactions. Unlike a custom exhibit in a museum, iPads afford certain interactions that users will expect.
      </p>
      <p>
        Games must be responsive. Passive tangibles are unable to provide ‘smart’ feedback, so the screen must be responsive to the player’s actions in the physical space. A consistent response can be difficult to achieve using an Osmo, because hands will naturally block portions of the camera’s vision. We’ve found that a consistent response can be achieved through fast image recognition, smart image analysis, and careful observation of how players move their hands. The lack of reliable, immediate, and consistent responses from the screen will be a roadblock that prohibits engagement.
      </p>
      <h1>Acknowledgements</h1>
      <p>
      We thank the administrative teams at Catherine Cook School and Francis W. Parker School for their support. We also thank all the children who have given us valuable feedback through testing. And we thank Eric Uchalik (www.euchalik.com) for designing the assets.
      </p>
      
      <h1>References</h1>
      <ol class="references">
      <!--
      <li id="bers-2008">Bers, M. (2008). <i>Blocks to Robots: Learning with Technology in the Early Childhood Classroom</i>. Teachers College Press.</li> 
      -->
      <li id="cuban-2009">Cuban, L. (2009). <i>Oversold and underused: Computers in the classroom</i>. Harvard University Press.</li>
      <li id="drwagon13">Chawla, K., Chiou, M., Sandes, A., &amp; Blikstein, P. (2013). Dr. Wagon: a 'stretchable' toolkit for tangible computer programming. In <i>Proc. Interaction Design and Children</i> (IDC'13), 561-564.</li>
      <li id="disessa-2000">diSessa, A. (2000). <i>Changing Minds: Computers, Learning, and Literacty.</i> MIT Press.</li>
      <li id="scratchjr13">Flannery, L.P., Silverman, B., Kazakoff, E.R., Bers, M.U., Bontá, P., &amp; Resnick, M. (2013). Designing ScratchJr: Support for early childhood learning through computer programming. In <i>Proc. Interaction Design and Children</i> (IDC'13), 1-10.</li>
      <li id="flanagan-2009">Flanagan, M. Critical play: radical game design. MIT press, 2009.</li>
      <li id="habgood-2011">Habgood, M.P.J., Ainsworth, S.E. Motivating children to learn effectively: Exploring the value of intrinsic integration in educational games. The Journal of the Learning Sciences 20.2 (2011): 169-206.</li>
      <li id="horn-2013">Horn, M.S. (2013). The role of cultural forms in tangible interaction design. In <i>Proc. Tangible, Embedded, and Embodied Interaction</i> (TEI'13).</li>
      <li id="schweikardt-2008">Schweikardt, E., Gross, M. D. (2008). The robot is the program: interacting with roBlocks. In TEI'08. 167-168.</li>
      <li id="topcodes">Horn, M. TopCode: Tangible Object Placement Codes. http://users.eecs.northwestern.edu/~mhorn/topcodes/</li>
      <li id="horn-2012">Horn, M.S., Crouser, R.J., &amp; Bers, M.U. (2012). Tangible interaction and learning: The case for a hybrid approach. <i>Pers. and Ubiq. Computing, 16</i>(4), 379-389.</li>
      <li id="kibo-2015">Sullivan, A., Elkin, M., Bers, M. U. (2015). KIBO robot demo: engaging young children in programming and engineering. In Proceedings of the 14th International Conference on Interaction Design and Children. 418-421.</li>
      <li id="roberto13">Horn, M.S., AlSulaiman, S., Koh, J. (2013). Translating Roberto to Omar: Computational literacy, stickerbooks, and cultural forms. In <i>Proc. IDC'13</i>, 120-127.</li>
      <li id="hour-of-code">Hour of Code. https://www.code.org/learn</li>
      <!-- <li id="horn-2014">Horn, M.S., Weintrop, D., and Routman, E. (2014). Programming in the Pond: A Tabletop Computer Programming Exhibit. In <i>Proc. ACM Human Factors in Computing Systems (CHI'14 extended abstracts).</i></li> -->
      <!-- <li id="kazakoff-2014">Kazakoff, E.R. &amp; Bers, M.U. (2014). Put your robot in, Put your robot out: Sequencing through programming robots in early childhood.  <i>Journal of Educational Computing Research, 50</i>(4).</li>  -->      
      <li id="mcnerney-2004">McNerney, T. (2004). From turtles to tangible programming bricks: explorations in physical language design. <i>Pers. and Ubiq. Computing, 8</i>(5), 326-337.</li>
      <li id="montemayor-2004">Montemayor, J., Druin, A., Chipman, G., Farber, A., &amp; Guha, M.L. (2004). Tools for children to create physical interactive StoryRooms. <i>Computers in Entertainment: Educating children through entertainment Part II, 2</i>(1). </li>
      <li id="nasir-2005">Nasir, N. I. S. (2005). Individual cognitive structuring and the sociocultural context: Strategy shifts in the game of dominoes. The Journal of the Learning Sciences, 14(1), 5-34.</li>
      <li id="norman-2012">Norman, D.A. The design of everyday things: Revised and expanded edition. Basic books, 2013.</li>
      <li id="oh-2013">Oh, H., Deshmane, A., Li, F., Han, J. Y., Stewart, M., Tsai, M., &amp; Oakley, I. (2013). The digital dream lab: tabletop puzzle blocks for exploring programmatic concepts. In <i>Proc. Tangible, Embedded and Embodied Interaction</i> (TEI'13)</li>
      <li id="osmo">Osmo. https://www.playosmo.com</li>
      <li id="papert-1980">Papert, S. (1980). <i>Mindstorms: Children, Computers, and Powerful Ideas.</i> New York: Basic Books. </li>
      <!-- <li id="nrc-2011">National Research Council. (2011). <i>Report of a Workshop of Pedagogical Aspects of Computational Thinking.</i> Washington, D.C.: The National Academies Press.</li> -->
      <li id="resnick-2009">Resnick, M., Maloney, J., Monroy-Hernández, A., Rusk, N., Eastmond, E., Brennan, K., Millner, A., Rosenbaum, E., Silver, J., Sliverman, B. &amp; Kafai, Y. (2009). Scratch: programming for all. <i>Communications of the ACM, 52</i>(11), 60-67.</li>
      <li id="sapounidis-2013">Sapounidis, T., &amp; Demetriadis, S. (2013). Tangible versus graphical user interfaces for robot programming: exploring cross-age children’s preferences. <i>Personal and ubiquitous computing, 17</i>(8), 1775-1786.</li>
      <li id="roblocks08">Schweikardt, E., &amp; Gross, M.D. (2008). The robot is the program: interacting with roBlocks. In <i>Proc. Tangible and Embedded Interaction</i> (TEI'08), 167-168.</li>

      <li id="sipitakiat-2012">Sipitakiat, A., &amp; Nusen, N. (2012). Robo-Blocks: designing debugging abilities in a tangible programming system for early primary school children. In <i>Proc. Interaction Design and Children</i> (IDC'12), 98-105.</li>
      <li id="snibbe-2009">Snibbe, S. S., Raffle, H. S. (2009). Social immersive media: pursuing best practices for multi-user interactive camera/projector exhibits. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 1447-1456.</li>
      <li id="stevens-2008">Stevens, R., Satwicz, T., &amp; McCarthy, L. (2008). In-game, in-room, in-world: Reconnecting video game play to the rest of kids’ lives. The ecology of games: Connecting youth, games, and learning, 9, 41-66.</li>
      <li id="weintrop-2013">Weintrop, D., &amp; Wilensky, U. (2013). RoboBuilder: A Computational Thinking Game. In <i>Proc. ACM Technical Symposium on Computer Science Education</i>, 736-736.</li>
      <li id="wyeth-2008">Wyeth, P. (2008). How young children learn to program with sensor, action, and logic blocks. <i>Journal of the Learning Sciences, 17</i>(4), 517-550.</li> 
      </ol>
<!--
McNerney, T. S. (2004). From turtles to Tangible Programming Bricks: explorations in physical language design. Personal and Ubiquitous Computing, 8(5), 326-337.

Schweikardt, Eric, and Mark D. Gross. "The robot is the program: interacting with roBlocks." Proceedings of the 2nd international conference on Tangible and embedded interaction. ACM, 2008.

Sullivan, Amanda, Mollie Elkin, and Marina Umaschi Bers. "KIBO robot demo: engaging young children in programming and engineering." Proceedings of the 14th International Conference on Interaction Design and Children. ACM, 2015.
-->

    </div>
    <div id="reference-details"></div>
  </body>
</html>
